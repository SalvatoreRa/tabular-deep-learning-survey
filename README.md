# tabular-deep-learning-survey



## Data transformation for neural network

### Homogeneous Data Encoding

| Date | Name | Paper | Code | 
| - | - | - | - |
| 2024 | CARTE | [CARTE: pretraining and transfer for tabular learning](https://proceedings.mlr.press/v235/kim24d.html) | [![Static Badge](https://badgen.net/badge/color/Code/black?label=)](https://github.com/soda-inria/carte) |
| 2024 | LM-IGTD | [LM-IGTD: a 2d image generator for low-dimensional and mixed-type tabular data to leverage the potential of convolutional neural networks](https://arxiv.org/abs/2406.14566) | -  |
| 2023 | ReConTab | [Recontab: Regularized contrastive representation learning for tabular data](https://arxiv.org/abs/2310.18541) | - |
| 2023 | HYTREL | [HYTREL: Hypergraph-enhanced Tabular Data Representation Learninga](https://arxiv.org/abs/2307.08623) | [![Static Badge](https://badgen.net/badge/color/Code/black?label=)](https://github.com/awslabs/hypergraph-tabular-lm) |
| 2022 | DWTM | [A Dynamic Weighted Tabular Method for Convolutional Neural Networks](https://arxiv.org/abs/2205.10386) |  [![Static Badge](https://badgen.net/badge/color/Code/black?label=)](https://github.com/AnonymousCIKM1/DWTM) |
| 2021 | IGTD | [Converting tabular data into images for deep learning with convolutional neural networks](https://www.nature.com/articles/s41598-021-90923-y) |  [![Static Badge](https://badgen.net/badge/color/Code/black?label=)](https://github.com/oeg-upm/TINTOlib-Documentation) [![Static Badge](https://badgen.net/badge/color/Code/black?label=)](https://github.com/zhuyitan/IGTD) |
| 2020 | VIME | [VIME: extending the success of self- and semi-supervised learning to tabular domain](https://proceedings.neurips.cc/paper_files/paper/2020/hash/7d97667a3e056acab9aaf653807b4a03-Abstract.html) |  [![Static Badge](https://badgen.net/badge/color/Code/black?label=)](https://github.com/jsyoon0823/VIME) [![Static Badge](https://badgen.net/badge/color/Code/black?label=)](https://github.com/Alcoholrithm/TabularS3L)|
| 2020 | Tabular Convolution (TAC)  | [A novel method for classification of tabular data using convolutional neural networks](https://www.biorxiv.org/content/10.1101/2020.05.02.074203.abstract) | - |
| 2020 | REFINED | [Converting tabular data into images for deep learning with convolutional neural networks](https://www.nature.com/articles/s41598-021-90923-y) | - |
| 2019 | SuperTML | [Supertml: Two-dimensional word embedding for the precognition on structured tabular data](http://openaccess.thecvf.com/content_CVPRW_2019/html/Precognition/Sun_SuperTML_Two-Dimensional_Word_Embedding_for_the_Precognition_on_Structured_Tabular_CVPRW_2019_paper.html) | [![Static Badge](https://badgen.net/badge/color/Code/black?label=)](https://github.com/oeg-upm/TINTOlib-Documentation)  [![Static Badge](https://badgen.net/badge/color/Code/black?label=)](https://github.com/EmjayAhn/SuperTML-pytorch)  |
| 2019 | DeepInsight | [DeepInsight: A methodology to transform a non-image data to an image for convolution neural network architecture](https://www.nature.com/articles/s41598-019-47765-6) | [![Static Badge](https://badgen.net/badge/color/Code/black?label=)](https://www.kaggle.com/code/markpeng/deepinsight-transforming-non-image-data-to-images) |



## Neural ensembles

| Date | Name | Paper | Code | 
| - | - | - | - |
| 2023 | HyperTab | [HyperTab: Hypernetwork Approach for Deep Learning on Small Tabular Datasets](https://arxiv.org/abs/2304.03543) | [![Static Badge](https://badgen.net/badge/color/Code/black?label=)](https://github.com/wwydmanski/hypertab) |

## Regularization

| Date | Name | Paper | Code | 
| - | - | - | - |
| 2025 | Harmonic loss| [Harmonic Loss Trains Interpretable AI Models](https://arxiv.org/abs/2502.01628v1) | [![Static Badge](https://badgen.net/badge/color/Code/black?label=)](https://github.com/ches-001/audio-segmenter)  |
| 2024 | sTabNet| [Escaping the Forest: Sparse Interpretable Neural Networks for Tabular Data](https://arxiv.org/abs/2410.17758v1) | [![Static Badge](https://badgen.net/badge/color/Code/black?label=)](https://github.com/SalvatoreRa/sTabNet)  |
| 2022 | Regularized pretraining | [Revisiting Pretraining Objectives for Tabular Deep Learning](https://arxiv.org/abs/2207.03208) | [![Static Badge](https://badgen.net/badge/color/Code/black?label=)](https://github.com/puhsu/tabular-dl-pretrain-objectives)  |
| 2022 | LSPIN| [Locally Sparse Neural Networks for Tabular Biomedical Data](https://proceedings.mlr.press/v162/yang22i.html) | [![Static Badge](https://badgen.net/badge/color/Code/black?label=)](https://github.com/jcyang34/lspin) |
| 2021 | Regularized tuned network| [Well-tuned Simple Nets Excel on Tabular Datasets](https://arxiv.org/abs/2106.11189) | [![Static Badge](https://badgen.net/badge/color/Code/black?label=)](https://github.com/machinelearningnuremberg/WellTunedSimpleNets)  |
| 2021 | Regularized cocktail| [Simple Modifications to Improve Tabular Neural Networks](https://arxiv.org/abs/2108.03214) | [![Static Badge](https://badgen.net/badge/color/Code/black?label=)](https://github.com/jrfiedler/xynn)  |
| 2021 | Regularized cocktail| [Muddling Label Regularization: Deep Learning for Tabular Datasets](https://arxiv.org/abs/2106.04462) | [![Static Badge](https://badgen.net/badge/color/Code/black?label=)](https://github.com/anonymousNeurIPS2021submission5254/SupplementaryMaterial)  |
| 2021 | LockOut| [Lockout: Sparse Regularization of Neural Networks](https://arxiv.org/abs/2107.07160) | - |
| 2019 | Cancelout| [CancelOut: A Layer for Feature Selection in Deep Neural Networks](https://dl.acm.org/doi/10.1007/978-3-030-30484-3_6) | [![Static Badge](https://badgen.net/badge/color/Code/black?label=)](https://github.com/unnir/CancelOut)  |
| 2018 | STG| [Feature Selection using Stochastic Gates](https://arxiv.org/abs/1810.04247) | [![Static Badge](https://badgen.net/badge/color/Code/black?label=)](https://yutaroyamada.com/stg/) [![Static Badge](https://badgen.net/badge/color/Code/black?label=)](https://github.com/runopti/stg) |
| 2018 | RLNs | [Regularization learning networks: deep learning for tabular datasets](https://proceedings.neurips.cc/paper_files/paper/2018/hash/500e75a036dc2d7d2fec5da1b71d36cc-Abstract.html) |  [![Static Badge](https://badgen.net/badge/color/Code/black?label=)](https://github.com/irashavitt/regularization_learning_networks) |
| 2017 | SNN| [Self-normalizing neural networks](https://proceedings.neurips.cc/paper_files/paper/2017/hash/5d44ee6f2c3f71b73125876103c8f6c4-Abstract.html) | [![Static Badge](https://badgen.net/badge/color/Code/black?label=)](https://www.kaggle.com/code/gulshanmishra/self-normalizing-neural-networks) [![Static Badge](https://badgen.net/badge/color/Code/black?label=)](https://github.com/bioinf-jku/SNNs) |



## Specialized architectures

### MLP alternatives

| Date | Name | Paper | Code | 
| - | - | - | - |
| 2024 | KANs 2.0 | [KAN 2.0: Kolmogorov-Arnold Networks Meet Science](https://arxiv.org/abs/2408.10205) | [![Static Badge](https://badgen.net/badge/color/Code/black?label=)](https://github.com/kindxiaoming/pykan)  |
| 2024 | KANs | [KAN: Kolmogorov-Arnold Networks](https://arxiv.org/abs/2404.19756) | [![Static Badge](https://badgen.net/badge/color/Code/black?label=)](https://github.com/kindxiaoming/pykan) [![Static Badge](https://badgen.net/badge/color/Code/black?label=)](https://paperswithcode.com/paper/kan-kolmogorov-arnold-networks) |
| 2022 | GANDALF | [GANDALF: Gated Adaptive Network for Deep Automated Learning of Features](https://arxiv.org/abs/2207.08548) | [![Static Badge](https://badgen.net/badge/color/Code/black?label=)](https://github.com/manujosephv/GATE) [![Static Badge](https://badgen.net/badge/color/Code/black?label=)](https://github.com/manujosephv/pytorch_tabular) |
| 2022 |DANets| [Danets: Deep abstract networks for tabular data classification and regression](https://ojs.aaai.org/index.php/AAAI/article/view/20309) | [![Static Badge](https://badgen.net/badge/color/Code/black?label=)](https://github.com/manujosephv/pytorch_tabular) [![Static Badge](https://badgen.net/badge/color/Code/black?label=)](https://github.com/WhatAShot/DANet) |
| 2016 | PNNs| [Product-based Neural Networks for User Response Prediction](https://arxiv.org/abs/1611.00144) | [![Static Badge](https://badgen.net/badge/color/Code/black?label=)](https://github.com/Atomu2014/product-nets) [![Static Badge](https://badgen.net/badge/color/Code/black?label=)](https://paperswithcode.com/paper/product-based-neural-networks-for-user) |



### MLP enhancements

| Date | Name | Paper | Code | 
| - | - | - | - |
| 2024 | sTabNet| [Escaping the Forest: Sparse Interpretable Neural Networks for Tabular Data](https://arxiv.org/abs/2410.17758v1) | [![Static Badge](https://badgen.net/badge/color/Code/black?label=)](https://github.com/SalvatoreRa/sTabNet)  |
| 2024 | xNet | [Cauchy activation function and XNet](https://arxiv.org/abs/2409.19221) | [![Static Badge](https://badgen.net/badge/color/Code/black?label=)](https://github.com/SalvatoreRa/tutorial/blob/main/artificial%20intelligence/FAQ.md#large-language-models:~:text=What%20are%20(Comple)XNet%20or%20Xnet%3F)  |
| 2024 | better by default| [Better by Default: Strong Pre-Tuned MLPs and Boosted Trees on Tabular Data](https://arxiv.org/abs/2407.04491) | [![Static Badge](https://badgen.net/badge/color/Code/black?label=)](https://github.com/dholzmueller/pytabkit)  |
| 2021 | Regularized cocktail| [Simple Modifications to Improve Tabular Neural Networks](https://arxiv.org/abs/2108.03214) | [![Static Badge](https://badgen.net/badge/color/Code/black?label=)](https://github.com/jrfiedler/xynn)  |
| 2021 | Regularized cocktail| [Muddling Label Regularization: Deep Learning for Tabular Datasets](https://arxiv.org/abs/2106.04462) | [![Static Badge](https://badgen.net/badge/color/Code/black?label=)](https://github.com/anonymousNeurIPS2021submission5254/SupplementaryMaterial)  |

### Fully differentiable

| Date | Name | Paper | Code | 
| - | - | - | - |
| 2024 | BiSHop | [Bishop: Bi-directional cellular learning for tabular data with generalized sparse modern hopfield model](https://proceedings.mlr.press/v235/xu24l.html) |  [![Static Badge](https://badgen.net/badge/color/Code/black?label=)](https://github.com/MAGICS-LAB/BiSHop) |
| 2024 | SwitchTab | [Switchtab: Switched autoencoders are effective tabular learners](https://ojs.aaai.org/index.php/AAAI/article/view/29523) | [![Static Badge](https://badgen.net/badge/color/Code/black?label=)](https://github.com/Alcoholrithm/TabularS3L) |
| 2024 | ExcelFormer | [Can a deep learning model be a sure bet for tabular prediction?](https://dl.acm.org/doi/abs/10.1145/3637528.3671893) | [![Static Badge](https://badgen.net/badge/color/Code/black?label=)](https://github.com/whatashot/excelformer) |
| 2023 | Trompt | [Trompt: Towards a better deep neural network for tabular data](https://proceedings.mlr.press/v202/chen23c.html) | - |
| 2021 | DNN2LR | [DNN2LR: Automatic Feature Crossing for Credit Scoring](https://arxiv.org/abs/2102.12036) | - |
| 2021 | SDTR | [SDTR: Soft Decision Tree Regressor for Tabular Data](https://ieeexplore.ieee.org/document/9393908) | - |
| 2021 | TabNet | [Tabnet: Attentive interpretable tabular learning](https://ojs.aaai.org/index.php/AAAI/article/view/16826) | [![Static Badge](https://badgen.net/badge/color/Code/black?label=)](https://github.com/dreamquark-ai/tabnet) |
| 2020 | NODE | [Neural oblivious decision ensembles for deep learning on tabular data](https://openreview.net/forum?id=r1eiu2VtwH) | [![Static Badge](https://badgen.net/badge/color/Code/black?label=)](https://github.com/manujosephv/pytorch_tabular) [![Static Badge](https://badgen.net/badge/color/Code/black?label=)](https://github.com/Qwicen/node) |
| 2020 | DCN V2 | [DCN V2: Improved Deep & Cross Network and Practical Lessons for Web-scale Learning to Rank Systems](https://arxiv.org/abs/2008.13535) | [![Static Badge](https://badgen.net/badge/color/Code/black?label=)](https://paperswithcode.com/paper/dcn-m-improved-deep-cross-network-for-feature) [![Static Badge](https://badgen.net/badge/color/Code/black?label=)](https://github.com/tensorflow/recommenders/blob/v0.5.1/tensorflow_recommenders/layers/feature_interaction/dcn.py) |
| 2020 | NON | [Network On Network for Tabular Data Classification in Real-world Applications](https://arxiv.org/abs/2005.10114) | - |
| 2020 | DNF-Net | [DNF-Net: A Neural Architecture for Tabular Data](https://arxiv.org/abs/2006.06465) | [![Static Badge](https://badgen.net/badge/color/Code/black?label=)](https://github.com/nini-lxz/DNF-Net) |
| 2018 | AutoInt| [AutoInt: Automatic Feature Interaction Learning via Self-Attentive Neural Networks](https://arxiv.org/abs/1810.11921) | [![Static Badge](https://badgen.net/badge/color/Code/black?label=)](https://deeptables.readthedocs.io/en/latest/) [![Static Badge](https://badgen.net/badge/color/Code/black?label=)](https://github.com/DeepGraphLearning/RecommenderSystems)  |
| 2018 | xDeepFM | [xDeepFM: Combining Explicit and Implicit Feature Interactions for Recommender Systems](https://arxiv.org/abs/1803.05170) | [![Static Badge](https://badgen.net/badge/color/Code/black?label=)](https://deeptables.readthedocs.io/en/latest/) [![Static Badge](https://badgen.net/badge/color/Code/black?label=)](https://github.com/Leavingseason/xDeepFM)  |
| 2017 | DeepFM | [DeepFM: A Factorization-Machine based Neural Network for CTR Prediction](https://arxiv.org/abs/1703.04247) | [![Static Badge](https://badgen.net/badge/color/Code/black?label=)](https://deeptables.readthedocs.io/en/latest/) [![Static Badge](https://badgen.net/badge/color/Code/black?label=)](https://github.com/reczoo/FuxiCTR)  |
| 2017 |      SDTS      | [Distilling a Neural Network Into a Soft Decision Tree](https://arxiv.org/abs/1711.09784) | [![Static Badge](https://badgen.net/badge/color/Code/black?label=)](https://paperswithcode.com/paper/distilling-a-neural-network-into-a-soft)  |
| 2017 | DCN | [Deep & Cross Network for Ad Click Predictions](https://arxiv.org/abs/1708.05123) | [![Static Badge](https://badgen.net/badge/color/Code/black?label=)](https://deeptables.readthedocs.io/en/latest/) [![Static Badge](https://badgen.net/badge/color/Code/black?label=)](https://paperswithcode.com/paper/deep-cross-network-for-ad-click-predictions)  |
| 2016 | Wide & Deep | [Wide & Deep Learning for Recommender Systems](https://arxiv.org/abs/1606.07792v1) | [![Static Badge](https://badgen.net/badge/color/Code/black?label=)](https://github.com/jrzaurin/pytorch-widedeep) [![Static Badge](https://badgen.net/badge/color/Code/black?label=)](https://paperswithcode.com/paper/wide-deep-learning-for-recommender-systems) [![Static Badge](https://badgen.net/badge/color/Code/black?label=)](https://deeptables.readthedocs.io/en/latest/) |

### Partly differentiable

| Date | Name | Paper | Code | 
| - | - | - | - |
| 2023 | TabR | [TabR: Tabular Deep Learning Meets Nearest Neighbors in 2023](https://arxiv.org/abs/2307.14338) | [![Static Badge](https://badgen.net/badge/color/Code/black?label=)](https://github.com/yandex-research/tabular-dl-tabr) |
| 2021 | BGNN | [Boost then Convolve: Gradient Boosting Meets Graph Neural Networks](https://arxiv.org/abs/2101.08543) | [![Static Badge](https://badgen.net/badge/color/Code/black?label=)](https://github.com/nd7141/bgnn) |
| 2019 | DeepGBM | [DeepGBM: A Deep Learning Framework Distilled by GBDT for Online Prediction Tasks](https://dl.acm.org/doi/10.1145/3292500.3330858) | [![Static Badge](https://badgen.net/badge/color/Code/black?label=)](https://github.com/motefly/DeepGBM) |
| 2019 | TabNN | [TabNN: A Universal Neural Network Solution for Tabular Data](https://openreview.net/forum?id=r1eJssCqY7) | - |


## Trasformer based

### Modified transformers

| Date | Name | Paper | Code | 
| - | - | - | - |
| 2025 | TabPFN v2 | [Accurate predictions on small data with a tabular foundation model](https://www.nature.com/articles/s41586-024-08328-6) | [![Static Badge](https://badgen.net/badge/color/Code/black?label=)](https://github.com/PriorLabs/TabPFN) |
| 2024 | UniTabE | [UniTabE: A Universal Pretraining Protocol for Tabular Foundation Model in Data Science](https://openreview.net/forum?id=6LLho5X6xV) | |
| 2024 | MambaTab | [MambaTab: A Plug-and-Play Model for Learning Tabular Data](https://arxiv.org/abs/2401.08867) | [![Static Badge](https://badgen.net/badge/color/Code/black?label=)](https://github.com/atik-ahamed/mambatab) |
| 2023 | TabPFN | [Tabpfn: A transformer that solves small tabular classification problems in a second](https://openreview.net/forum?id=cp5PvcI6w8_) |  [![Static Badge](https://badgen.net/badge/color/Code/black?label=)](https://github.com/PriorLabs/TabPFN) |
| 2023 | Xtab | [Xtab: Cross-table pretraining for tabular transformers](https://proceedings.mlr.press/v202/zhu23k.html) |  [![Static Badge](https://badgen.net/badge/color/Code/black?label=)](https://github.com/BingzhaoZhu/XTab) |
| 2022 | LF-Transformer | [LF-Transformer: Latent Factorizer Transformer for Tabular Learning](https://ieeexplore.ieee.org/document/10401112) | [![Static Badge](https://badgen.net/badge/color/Code/black?label=)](https://github.com/kwangtekNa/LF-Transformer/) |
| 2022 | TransTab| [Transtab: Learning transferable tabular transformers across tables](https://proceedings.neurips.cc/paper_files/paper/2022/hash/1377f76686d56439a2bd7a91859972f5-Abstract-Conference.html) | [![Static Badge](https://badgen.net/badge/color/Code/black?label=)](https://transtab.readthedocs.io/en/latest/) [![Static Badge](https://badgen.net/badge/color/Code/black?label=)](https://github.com/RyanWangZf/transtab) |
| 2022 | SAINTENS | [SAINTENS: Self-Attention and Intersample Attention Transformer for Digital Biomarker Development Using Tabular Healthcare Real World Data](https://pubmed.ncbi.nlm.nih.gov/35592984/) | - |
| 2022 | TableFormer | [TableFormer: Robust Transformer Modeling for Table-Text Encoding](https://arxiv.org/abs/2203.00274) |  [![Static Badge](https://badgen.net/badge/color/Code/black?label=)](https://github.com/google-research/tapas) |
| 2022 | SAINT | [SAINT: Improved neural networks for tabular data via row attention and contrastive pre-training](https://openreview.net/forum?id=FiyUTAy4sB8) |  [![Static Badge](https://badgen.net/badge/color/Code/black?label=)](https://github.com/somepago/saint) |
| 2022 | GatedTabTransformer | [The GatedTabTransformer. An enhanced deep learning architecture for tabular modeling](https://arxiv.org/abs/2201.00199) | [![Static Badge](https://badgen.net/badge/color/Code/black?label=)](https://github.com/radi-cho/GatedTabTransformer) |
| 2021 | NPT | [Self-Attention Between Datapoints: Going Beyond Individual Input-Output Pairs in Deep Learning](https://arxiv.org/abs/2106.02584) |  [![Static Badge](https://badgen.net/badge/color/Code/black?label=)](https://github.com/OATML/Non-Parametric-Transformers) |
| 2021 | ARM-Net | [ARM-Net: Adaptive Relation Modeling Network for Structured Data](https://arxiv.org/abs/2107.01830) | [![Static Badge](https://badgen.net/badge/color/Code/black?label=)](https://github.com/nusdbsystem/ARM-Net) |
| 2021 | FT-Transformer | [Revisiting deep learning models for tabular data](https://proceedings.neurips.cc/paper_files/paper/2021/hash/9d86d83f925f2149e9edb0ac3b49229c-Abstract.html) | [![Static Badge](https://badgen.net/badge/color/Code/black?label=)](https://github.com/yandex-research/rtdl) |
| 2021 | Fair-TabNet | [Fairness in TabNet Model by Disentangled Representation for the Prediction of Hospital No-Show](https://arxiv.org/abs/2103.04048) | - |
| 2021 | TabNet | [Tabnet: Attentive interpretable tabular learning](https://ojs.aaai.org/index.php/AAAI/article/view/16826) | [![Static Badge](https://badgen.net/badge/color/Code/black?label=)](https://github.com/dreamquark-ai/tabnet) |
| 2020 | TabTransformer | [Tabtransformer: Tabular data modeling using contextual embeddings](https://arxiv.org/abs/2012.06678) | [![Static Badge](https://badgen.net/badge/color/Code/black?label=)](https://github.com/lucidrains/tab-transformer-pytorch) |
| 2020 | RPT | [RPT: Relational Pre-trained Transformer Is Almost All You Need towards Democratizing Data Preparation](https://arxiv.org/abs/2012.02469) | - |

### Data adaptation

| Date | Name | Paper | Code | 
| - | - | - | - |
| 2022 | FORTAP | [FORTAP: Using Formulas for Numerical-Reasoning-Aware Table Pretraining](https://arxiv.org/abs/2106.03096) | [![Static Badge](https://badgen.net/badge/color/Code/black?label=)](https://github.com/microsoft/TUTA_table_understanding) |
| 2021 | TabularNet | [TabularNet: A Neural Network Architecture for Understanding Semantic Structures of Tabular Data](https://arxiv.org/abs/2106.03096) | - |
| 2021 | DODUO | [Annotating Columns with Pre-trained Language Models](https://arxiv.org/abs/2104.01785) | [![Static Badge](https://badgen.net/badge/color/Code/black?label=)](https://github.com/megagonlabs/doduo) |
| 2021 | MATE | [MATE: Multi-view Attention for Table Transformer Efficiency](https://arxiv.org/abs/2109.04312) | [![Static Badge](https://badgen.net/badge/color/Code/black?label=)](https://github.com/google-research/tapas) |
| 2021 | TABBIE | [TABBIE: Pretrained Representations of Tabular Data
](https://arxiv.org/abs/2105.02584) | [![Static Badge](https://badgen.net/badge/color/Code/black?label=)](https://github.com/SFIG611/tabbie) |
| 2021 | DECO | [Exploring Decomposition for Table-based Fact Verification](https://arxiv.org/abs/2109.11020) | [![Static Badge](https://badgen.net/badge/color/Code/black?label=)](https://github.com/arielsho/decomposition-table-reasoning) |
| 2020 | TAPAS | [TAPAS: Weakly Supervised Table Parsing via Pre-training](https://arxiv.org/abs/2004.02349) | [![Static Badge](https://badgen.net/badge/color/Code/black?label=)](https://github.com/google-research/tapas) |
| 2020 | TUTA | [TUTA: Tree-based Transformers for Generally Structured Table Pre-training](https://arxiv.org/abs/2010.12537) | [![Static Badge](https://badgen.net/badge/color/Code/black?label=)](https://github.com/microsoft/TUTA_table_understanding) |
| 2020 | TaBERT | [TaBERT: Pretraining for Joint Understanding of Textual and Tabular Data](https://arxiv.org/abs/2005.08314) | [![Static Badge](https://badgen.net/badge/color/Code/black?label=)](https://github.com/facebookresearch/TaBERT) |
| 2020 | TURL | [TURL: Table Understanding through Representation Learning](https://arxiv.org/abs/2006.14806) | [![Static Badge](https://badgen.net/badge/color/Code/black?label=)](https://github.com/sunlab-osu/TURL) |
| 2020 | TableGPT | [TableGPT: Few-shot Table-to-Text Generation with Table Structure Reconstruction and Content Matching](https://aclanthology.org/2020.coling-main.179/) | [![Static Badge](https://badgen.net/badge/color/Code/black?label=)](https://github.com/syw1996/TableGPT) |
| 2020 | ToTTo | [TToTTo: A Controlled Table-To-Text Generation Dataset](https://arxiv.org/abs/2004.14373) | [![Static Badge](https://badgen.net/badge/color/Code/black?label=)](https://github.com/google-research-datasets/ToTTo) |
| 2019 | TabFact | [TabFact: A Large-scale Dataset for Table-based Fact Verification](https://arxiv.org/abs/1909.02164) | [![Static Badge](https://badgen.net/badge/color/Code/black?label=)](https://github.com/wenhuchen/Table-Fact-Checking) |

## Large language models

| Date | Name | Paper | Code | 
| - | - | - | - |
| 2024 | SERVAL | [SERVAL: Synergy Learning between Vertical Models and LLMs towards Oracle-Level Zero-shot Medical Prediction](https://arxiv.org/abs/2403.01570v2) | - |
| 2024 | Table meets LLM | [Table Meets LLM: Can Large Language Models Understand Structured Table Data? A Benchmark and Empirical Study](https://arxiv.org/abs/2305.13062v5) | [![Static Badge](https://badgen.net/badge/color/Code/black?label=)](https://github.com/Y-Sui/Table-meets-LLM) |
| 2023 | TableGPT | [TableGPT: Towards Unifying Tables, Nature Language and Commands into One GPT](https://arxiv.org/abs/2307.08674) | - |
| 2023 | TableLlama | [TableLlama: Towards Open Large Generalist Models for Tables](https://arxiv.org/abs/2311.09206) | [![Static Badge](https://badgen.net/badge/color/Code/black?label=)](https://osu-nlp-group.github.io/TableLlama/)  [![Static Badge](https://badgen.net/badge/color/Code/black?label=)](https://huggingface.co/osunlp/TableLlama) [![Static Badge](https://badgen.net/badge/color/Code/black?label=)](https://github.com/OSU-NLP-Group/TableLlama)|
| 2023 | UniTabPT | [Bridge the Gap between Language models and Tabular Understanding](https://arxiv.org/abs/2302.09302) | - |
| 2023 | UTP | [Testing the Limits of Unified Sequence to Sequence LLM Pretraining on Diverse Table Data Tasks](https://arxiv.org/abs/2310.00789) | - |
| 2023 | TABLET | [TABLET: Learning From Instructions For Tabular Data](https://arxiv.org/abs/2304.13188) |  [![Static Badge](https://badgen.net/badge/color/Code/black?label=)](https://paperswithcode.com/paper/tablet-learning-from-instructions-for-tabular) |
| 2023 | Summary boost | [Language models are weak learners](https://arxiv.org/abs/2306.14101) |  - |
| 2023 | TabFMs | [Towards Foundation Models for Learning on Tabular Data](https://openreview.net/forum?id=hz2zhaZPXm) |  - |
| 2023 | Unipredict | [UniPredict: Large Language Models are Universal Tabular Classifiers](https://arxiv.org/abs/2310.03266) |  - |
| 2023 | serializeLLM | [Towards Better Serialization of Tabular Data for Few-shot Classification with Large Language Models](https://arxiv.org/abs/2312.12464) |  - |
| 2023 | FinPT | [FinPT: Financial Risk Prediction with Profile Tuning on Pretrained Foundation Models](https://arxiv.org/abs/2308.00065) |  [![Static Badge](https://badgen.net/badge/color/Code/black?label=)](https://github.com/yuweiyin/finpt) |
| 2023 | DATER | [Large Language Models are Versatile Decomposers: Decompose Evidence and Questions for Table-based Reasoning](https://arxiv.org/abs/2301.13808) | [![Static Badge](https://badgen.net/badge/color/Code/black?label=)](https://github.com/alibabaresearch/damo-convai) |
| 2023 | DocMath-Eval | [DocMath-Eval: Evaluating Math Reasoning Capabilities of LLMs in Understanding Long and Specialized Documents](https://arxiv.org/abs/2311.09805) | [![Static Badge](https://badgen.net/badge/color/Code/black?label=)](https://github.com/yale-nlp/docmath-eval) |
| 2023 | TableLLM | [TabLLM: Few-shot Classification of Tabular Data with Large Language Models](https://arxiv.org/abs/2312.16702) | [![Static Badge](https://badgen.net/badge/color/Code/black?label=)](https://github.com/Leolty/tablellm) |
| 2023 | MediTab | [MediTab: Scaling Medical Tabular Data Predictors via Data Consolidation, Enrichment, and Refinement](https://arxiv.org/abs/2305.12081) | [![Static Badge](https://badgen.net/badge/color/Code/black?label=)](https://github.com/ryanwangzf/meditab) |
| 2023 | ZeroTS | [Large Language Models Are Zero-Shot Time Series Forecasters](https://arxiv.org/abs/2310.07820) | [![Static Badge](https://badgen.net/badge/color/Code/black?label=)](https://github.com/ngruver/llmtime) |
| 2022 | Tabular representation | [Tabular Representation, Noisy Operators, and Impacts on Table Structure Understanding Tasks in LLMs](https://arxiv.org/abs/2310.10358) | - |
| 2022 | TabLLM | [TabLLM: Few-shot Classification of Tabular Data with Large Language Models](https://arxiv.org/abs/2210.10723) | [![Static Badge](https://badgen.net/badge/color/Code/black?label=)](https://github.com/clinicalml/TabLLM) |
| 2022 | LIFT | [LIFT: Language-Interfaced Fine-Tuning for Non-Language Machine Learning Tasks](https://arxiv.org/abs/2206.06565) | [![Static Badge](https://badgen.net/badge/color/Code/black?label=)](https://github.com/uw-madison-lee-lab/languageinterfacedfinetuning) |
| 2022 | OmniTab | [OmniTab: Pretraining with Natural and Synthetic Data for Few-shot Table-based Question Answering](https://arxiv.org/abs/2207.03637) | [![Static Badge](https://badgen.net/badge/color/Code/black?label=)](https://github.com/jzbjyb/omnitab) |
| 2022 | PromptCast | [PromptCast: A New Prompt-based Learning Paradigm for Time Series Forecasting](https://arxiv.org/abs/2210.08964) | [![Static Badge](https://badgen.net/badge/color/Code/black?label=)](https://github.com/haounsw/pisa) |
| 2022 | FEVEROUS | [FEVEROUS: Fact Extraction and VERification Over Unstructured and Structured information](https://arxiv.org/abs/2106.05707) | [![Static Badge](https://badgen.net/badge/color/Code/black?label=)](https://github.com/Raldir/FEVEROUS) |